proxyRestPort: 8093
proxyGrpcPort: 8100
cacheRestPort: 8094
cacheGrpcPort: 8095

metrics:
  metricsPath: "/monitoring/prometheus/metrics"
  # Whether to add model name and version as prometheus labels
  modelLabels: false

modelProvider:
  type: diskProvider
  baseDir: "./model_repo"
#modelProvider:
#  type: s3Provider
#  s3:
#    bucket: foo
#    basePath: models/foo/bar

modelCache:
  hostModelPath: "./models"
  size: 30000

serving:
  servingModelPath: "/models"
  grpcHost: "localhost:8500"
  restHost: "http://localhost:8501"
  maxConcurrentModels: 2
  grpcConfigTimeout: 10 # timeout in seconds
  grpcPredictTimeout: 60
  metricsPath: "/monitoring/prometheus/metrics"

proxy:
  replicasPerModel: 3
  grpcTimeout: 10

serviceDiscovery:
  #### CONSUL ####
  #type: consul
  #heartbeatTTL: 5
  #consul:
  #  serviceName: tfservingcache
  #  serviceId: foo1
  #### ETCD ####
  #type: etcd
  #heartbeatTTL: 5
  #etcd:
  #  serviceName: tfservingcache
  #  endpoints: ["localhost:2379"]
  #  allowLocalhost: true
  #  authorization:
  #    username: root
  #    password: foobar
  type: k8s
  k8s:
    # field selector for k8s TF serving cache pods
    fieldSelector:
      metadata.name: tf-serving-cache
    portNames:
      grpcCache: grpccache
      httpCache: httpcache
